---
title: "Bellabeat Case Study Report"
author: "Nathan"
date: "2023-07-27"
output: html_document
---

# Step 1: Ask
## Business Task

This analysis was initiated by Urška Sršen, co-founder of Bellabeat. Sršen knows that an analysis of available data on consumers' smart device usage would reveal opportunities for the company to grow, and has provided the following business task:

> Analyse smart device usage data to gain insight into how people are already using smart devices, then generate high-level recommendations for how these insights can inform the marketing strategy for one Bellabeat product.

## Key Stakeholders

* Urška Sršen
  + Co-founder of Bellabeat
  + Initiator of this analysis
* Bellabeat marketing team
  + Intended audience for my presentation
  + Will use my insights to guide marketing strategies

# Step 2: Prepare
## Setting up my tools
### Selecting my tools

For this analysis I wanted a tool or set of tools with the following features:

* Sufficient power enough to handle large data sets, e.g. FitBit data tables with >1M observations
* Functions for data manipulation, e.g. loading, cleaning and combining data sets
* Functions for data analysis, e.g. regression analysis and statistical analysis
* Functions for data visualisation, e.g. plotting
* Methods for storing the details of my analysis methodology separate from the data itself, e.g. separate source code files, as opposed to macros stored within spreadsheet files
* Methods for generating reports from my analysis with as little repetition of work as possible, e.g. inline markdown languages, or Page Layout views in spreadsheet applications
* A straightforward learning process and user interface, e.g. spreadsheet tools typically have a single "Add Chart" tool under which all of their powerful charting options can be found; contrast this with learning to download, enable, and finally use the ggplot2 R library

With these requirements in mind, I considered three tools: R, spreadsheets, and databases:

|Feature|R|Spreadsheets|Databases|
|:------------------------------|:---:|:---:|:---:|
| Power for large data sets     | Yes | No  | Yes |
| Data manipulation tools       | Yes | Yes | Yes |
| Data analysis tools           | Yes | Yes | No  |
| Data visualisation tools      | Yes | Yes | No  |
| Separate analysis files       | Yes | No  | Yes |
| Streamlined report generation | Yes | No  | No  |
| Straightforward to learn      | No  | Yes | No  |

Clearly, R is the best single tool for this analysis. R lacks the straightfoward operation of spreadsheet tools, and I will need to learn libraries and programming techniques as I do my analysis, but this is acceptable given my prior experience with other programming languages like Python. 

Note: Python itself was not considered for this analysis: while it shares most of the features, advantages, and disadvantages of R, I'm already familiar with Python and wanted to use this case study to familiarise myself with R instead

### Setting up my RStudio environment

The first preparation stage involves setting up my RStudio environment for my analysis.

The R chunk below automatically loads all packages included in the "rqd_pkgs" list, installing them first if required: this ensures all packages can be loaded by other analysts replicating my work, and minimises the effort required to modify the package list.

```{r setup, include=FALSE, results='hide'}
# Set up knitting options with the knitr package
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	results = 'hide',
	warning = FALSE
)

# Load all required packages
print("Loading packages...")

rqd_pkgs <- c(
  "dplyr",
  "anytime",
  "tidyverse",
  "janitor",
  "readr",
  "skimr",
  "tibble",
  "ggplot2",
  "gridExtra",
  "ggpubr",
  "kableExtra",
  "purrr"
)

lapply(rqd_pkgs, function(pkg) {
  if(!requireNamespace(pkg, quietly = FALSE)) {
    cran_mirror <- "https://cran.r-project.org"
    install.packages(as.character(pkg), repos = cran_mirror)
  }
  library(pkg, character.only = TRUE)
})
rm(rqd_pkgs)
print("Loading packages complete.")
```

```{r prep-set-dir}
# Set the working directory of the R markdown environment to match that of the console
dir <- "/Users/nathanweaver/Documents/GitHub/Bellabeat Case Study"
setwd(dir)
cat("Set working directory to:", dir, "\n")

```

## Getting the data

For this data analysis, I'll be making use of one public data set specified by Sršen, plus additional data sets as required to address any limitations found in that dataset.

The data set specified by Sršen is the [FitBit Fitness Tracker Data Set](https://www.kaggle.com/datasets/arashnic/fitbit). This is a public data set available under the [CC0 License](https://creativecommons.org/share-your-work/public-domain/cc/) via [Kaggle user Mobius](https://www.kaggle.com/arashnic).

For the initial analysis, the data set was downloaded in its entirety from Kaggle and stored locally on my computer. This provided a baseline for analysis, with any modifications to file names, folder re-structuring, or removal of unnecessary data tables to be conducted after I'm familiar with the raw data.

The raw CSV files in the dataset were loaded directly into the environment as data frames.

```{r prep-load-data-cleaned}
# Load all CSVs in the source directory into the environment
csv_dir <- "Fitabase_Data_Cleaned"
paths_dfs <- list.files(csv_dir, pattern = "*.csv", full.names = TRUE)

df_names <- paths_dfs %>%
  basename() %>%
  tools::file_path_sans_ext() 

for (i in 1:length(df_names)) {
  assign(df_names[i], read_csv(paths_dfs[i]))
}
rm(i, paths_dfs)
```

## Understanding the data
### Overview

The database contains data on the following features of the FitBit devices:

| Feature                 | Units                  | Sampling Rate            |
|:------------------------|:-----------------------|:-------------------------|
| BMI                     | BMI                    | Manual/automatic logging |
| Body Weight             | kg                     | Manual/automatic logging |
| Body Fat                | %                      | Manual/automatic logging |
| Calorie burn            | Calories               | 1 minute                 |
| Distance                | Unknown                | 1 minute                 |
| Heart Rate              | Beats per Minute (BPM) | 5 seconds                |
| Intensity (of exercise) | Factor, 0 to 3         | 1 minute                 |
| METs (during exercise)  | METs                   | 1 minute                 |
| Sleep                   | Factor, 1 to 3         | 1 minute                 |
| Steps                   | Steps                  | 1 minute                 |


Some details of the data gathering are not yet clear to me:

* The real-world meanings of the "Intensity" factor variable levels; presumably 3 is maximum intensity and 0 is inactivity.
* The real-world meanings of the "Sleep" factor variable levels are; presumably it indicates "quality of sleep", with 3 being best.
* What triggers the non-manual reports; presumably it's logged from another device, like a body composition analyser.

### Inconsistent and misleading file names

The file names in the data set present the following issues:

* Unclear if data is source or summarized, e.g. "minuteCaloriesNarrow_merged.csv" is source data, while "dailyCalories_merged.csv" is summarized data
* Summarized data not always tied to specific features, e.g. "dailyActivities_merged.csv" contains data summarized from multiple features: there is no "Activity" feature with an associated source data set.
* Data shape unclear, e.g. "minuteCaloriesNarrow_merged.csv" and "dailyCalories_merged.csv" are both tall data, while "minuteIntensitiesWide_merged.csv" and "dailyIntensities_merged.csv" are both wide data
* Data sampling rate unclear, e.g. "minuteSleep_merged.csv" compared to "daySleep_merged.csv"
* Feature is not first in the file name, affecting file sort operations, e.g. "minuteSleep_merged.csv" is sorted closer to "minuteStepsNarrow_merged.csv" than to the related "daySleep_merged.csv"
* All files are suffixed with "_merged", so no distinction is made by this information and it could be dropped

To correct each of these issues, I'll rename the files using this naming convention:

> [feature]\_[src/sum]\_[interval]\_[shape].[filetype]

For example, "sleepDay_merged.csv" will be renamed to "sleep_sum_days_wide.csv".

### Inconsistent variable names

All variables in the data set will be changed from CapitalisedCase to snake_case, by convention and to address an issue with inconsistently-capitalised variables (e.g. logId).

### Inappropriate variable types

Some of the tables in the data set use variables of a type unsuitable for analysis. These variables and their required modifications are tabulated below:

| Variable       | Original Type | Updated Type | Reason |
|:---------------|:--------------|:-------------|:-------|
| ActivityDay    | chr           | datetime     | Cannot perform datetime operations on chr variables |
| ActivityHour   | chr           | datetime     | Cannot perform datetime operations on chr variables |
| ActivityMinute | chr           | datetime     | Cannot perform datetime operations on chr variables |
| Date           | chr           | datetime     | Cannot perform datetime operations on chr variables |
| Id             | num           | chr          | Disable scientific notation and numerical operations (IDs are not a numeric value) |
| LogId          | num           | chr          | Disable scientific notation and numerical operations (IDs are not a numeric value) |
| SleepDay       | chr           | datetime     | Cannot perform datetime operations on chr variables |
| Time           | chr           | datetime     | Cannot perform datetime operations on chr variables |

### Missing context for numeric variables

All of the numeric variables in the data set have clearly defined units except for "Distance". Distance does not appear to have a source data table: it's only included in the "activity_sum_wide_days" and "intensity_sum_wide_days" tables, and only as summary data grouped via Intensity level. Daily values between 0 and 1 are present, so it seems reasonable to assume this is either kilometers or miles, as opposed to meters or feet. Miles and kilometers represent the same information on slightly different scales, so the analysis should not be affected as long as the units are consistent across tables, which they appear to be. I will therefore assume the distances are given in kilometers for this analysis.

### Missing context for factor variables

Two variables in the data set, "Intensity" (for exercise) and "Value" (for sleep), are numerical factors with no defined range. For these factors, I couldn't tell from the data alone whether all possible values that a FitBit can record are present. The values for exercise intensity, for example, range from 0 to 3; it could have been the case that the FitBits used only generate four levels of intensity, but it could just as easily have been that the values go up to 100 (i.e. a percentage). This had clear implications for the analysis: if 3 was the max, records of 3 indicated users wear their FitBits while exercising as hard as they can, whereas if 100 was the max, records of 3 indicated users wear their FitBits while sitting on the couch as hard as they can. The meaning of these variables had to be validated before the analysis could continue.

#### Validating "Exercise Intensity" by use of R

I'll start by determining the range of values present in the source Intensity data:

``` {r prep-get-intensity-range, results = 'markdown'}
# Display all unique Exercise Intensity values
print(unique(intensity_src_mins_tall$Intensity))

```

The "activity_sum_days_wide" table provided some context clues as to what these four levels might mean: the table summarises Intensity data into four new variables which, based on their names, appear to be associated with intensity levels like so:

1. Sedentary Minutes
2. Lightly Active Minutes
3. Fairly Active Minutes
4. Very Active Minutes

I confirmed this naming convention by using it to reconstruct the daily summary data in "activity_sum_days_wide", then comparing the two tables:

```{r prep-compare-intensity-data, results = 'markdown'}
# Reconstruct the summary intensity data for comparison with the original
activity_sum_days_wide_test <- intensity_src_mins_tall %>%
    mutate(activity_date_floored = floor_date(mdy_hms(ActivityMinute), unit = "days")) %>%
    group_by(Id, activity_date_floored) %>%
    summarize(
        minutes_sedentary      = sum(case_when(Intensity == 0 ~ 1, TRUE ~ 0)),
        minutes_lightly_active = sum(case_when(Intensity == 1 ~ 1, TRUE ~ 0)),
        minutes_fairly_active  = sum(case_when(Intensity == 2 ~ 1, TRUE ~ 0)),
        minutes_very_active    = sum(case_when(Intensity == 3 ~ 1, TRUE ~ 0))
    ) %>%
    mutate(Id_ActivityDate_UID = paste(Id, activity_date_floored, sep = "_")) %>%
    arrange(Id, activity_date_floored, Id_ActivityDate_UID)

# Compare both versions of the data and return any dates with different values
intensity_daily_comp <- activity_sum_days_wide %>%
    mutate(ActivityDate_floored = floor_date(mdy(ActivityDate), unit = "days")) %>%
    mutate(Id_ActivityDate_UID = paste(Id, ActivityDate_floored, sep = "_")) %>%
    with(merge(
        .,
        activity_sum_days_wide_test,
        by = c("Id_ActivityDate_UID"),
        all = TRUE
    )
    ) %>%
    mutate(diff_minutes_sedentary      = minutes_sedentary      - SedentaryMinutes     ) %>%
    mutate(diff_minutes_lightly_active = minutes_lightly_active - LightlyActiveMinutes ) %>%
    mutate(diff_minutes_fairly_active  = minutes_fairly_active  - FairlyActiveMinutes  ) %>%
    mutate(diff_minutes_very_active    = minutes_very_active    - VeryActiveMinutes    ) %>%
    select(
        Id_ActivityDate_UID,
        diff_minutes_sedentary,
        diff_minutes_lightly_active,
        diff_minutes_fairly_active,
        diff_minutes_very_active
    ) %>%
    filter(!(diff_minutes_sedentary == 0 & 
                 diff_minutes_lightly_active == 0 & 
                 diff_minutes_fairly_active == 0 & 
                 diff_minutes_very_active == 0)
    ) %>%
    arrange(Id_ActivityDate_UID)

# For this table, glimpse() shows enough to demonstrate the validity of the method
cat("Printing all rows with non-zero diff values:\n")
glimpse(intensity_daily_comp)
rm(activity_sum_days_wide_test, intensity_daily_comp)

```

The approach above appears to work perfectly, with the exception of the "sedentary minutes" calculation, which is consistently higher in my version.

I think its safe to conclude that I got the mapping correct, given that:

a) It's consistently higher by at least 6 hours, which appears caused by my method counting time asleep as "sedentary minutes", which is reasonable
b) Reversing the order of the mapping produces entirely wrong results.

That being said, I still don't know if these are the categories FitBits work in, not another naming convention that the data authors came up with, and I don't know if all FitBit models work this way, so let's do something I should have done from the start: read the manuals.

#### Validating "Exercise Intensity" by reading of manuals

Activity trackers like FitBits detect activity intensity partly by measuring the user's heart rate while exercising: a higher heart rate corresponds with a higher degree of exertion. As of April 2016, the three latest FitBit models with heart-rate tracking were:

* FitBit Blaze [(released January 2016)](https://www.youtube.com/watch?v=3k3DNT54NkA)
* FitBit Charge HR [(released January 2015)](https://blog.fitbit.com/charge-hr-and-surge-available-now-plus-new-charge-colors/)
* FitBit Surge [(released January 2015)](https://blog.fitbit.com/charge-hr-and-surge-available-now-plus-new-charge-colors/)

A quick look through the product manuals for each model confirms they all break down user activity into four default heart-rate zones:

|Product|HR Zone 1|HR Zone 2|HR Zone 3|HR Zone 4|
|:------|:----:|:----:|:----:|:----:|
|[FitBit Blaze](https://staticcs.fitbit.com/content/assets/help/manuals/manual_blaze_en_US.pdf)           |"Out of Zone"|"Fat burn"|"Cardio"|"Peak"|
|[FitBit Charge HR](https://staticcs.fitbit.com/content/assets/help/manuals/manual_charge_hr_en_US.pdf)   |"Out of Zone"|"Fat burn"|"Cardio"|"Peak"|
|[FitBit Surge](https://myhelp.fitbit.com/resource/manual_surge_en_US)                                    |"Out of Zone"|"Fat burn"|"Cardio"|"Peak"|

While these aren't exactly the same terms as used in the data set, they're clearly related - "Out of Zone" equates to "Sedentary", for example. 

All three FitBit manuals also make the same claim that the default zones are "based on American Heart Association recommendations". Even without [validating that claim](https://www.heart.org/en/healthy-living/fitness/fitness-basics/aha-recs-for-physical-activity-in-adults), it indicates to me that the reasoning behind each zone is not arbitrary, and is consistent across devices, so I think I can assume any other FitBit models circa 2016 would follow the same classification scheme.

At this point, I'm satisfied that the below are the only four intensity levels I need to consider when analysing the data set, regardless of what models of FitBits were being used:

0. Sedentary Minutes
1. Lightly Active Minutes
2. Fairly Active Minutes
3. Very Active Minutes

#### Validating "Sleep Quality" by use of R _and_ reading of manuals

As with exercise intensity, I start by determining the range of values present in the data:

``` {r prep-get-sleep-value-range, results = 'markdown'}
# Display all unique Sleep Value values
print(unique(sleep_src_mins_tall$value))

```

The values for sleep quality range from 1 to 3. The summary data tables for sleep quality introduce only two new variable names: "Total Time In Bed", and "Total Minutes Asleep". There's not a valid name for each level of factor like there was for exercise, so in this case we go straight back to the manuals:

* Blaze: tracks "both your time spent asleep and your sleep quality"
* Charge HR: tracks "the hours you sleep and your movement during the night"
* Surge: tracks "the hours you sleep and your movement during the night"

Further poking around the FitBit help pages on [how to track sleep stats](https://help.fitbit.com/articles/en_US/Help_article/1314.htm) and [what they all mean](https://help.fitbit.com/articles/en_US/Help_article/2163.htm) reveals that different devices track slightly different data if they have heart rate tracking:

* No HR tracking: Generic sleep quality tracking with "Time spent awake, restless, and asleep" categories
* HR tracking: Sleep stage tracking with "Light Sleep, Deep Sleep, and REM Sleep" stages

The help pages also single out the Charge HR and the Surge as the only HR-tracking FitBits to _not_ have full sleep stage tracking, leaving the Blaze as the only device from this time period with that feature. Blaze aside, motion-based sleep quality tracking appears to go all the way back to the [FitBit One](https://myhelp.fitbit.com/s/products?language=en_US&p=one). Given this information, it seems fair to assume the following mapping for the sleep data:

* 1: Awake
* 2: Restless
* 3: Asleep

As with the intensity data, I confirmed this by reconstructing the original summary data using this mapping. In practice it turns out I had the mapping inverted, and actually the following was used:

* 1: Asleep
* 2: Restless
* 3: Awake

This appears to be read as "1 is highest-quality sleep, 3 is worst-quality". I was able to recreate the existing sleep_src_mins_tall table almost perfectly using this mapping:

```{r prep-compare-sleep-value-data, results = 'markdown'}
# Reconstruct the summary sleep data for comparison with the original
sleep_sum_days_wide_test <- sleep_src_mins_tall %>%
    # mutate(date_typed = mdy_hms(date)) %>%
    mutate(date_floored = floor_date(mdy_hms(date), unit = "days")) %>%
    # Sum time asleep for each Log ID
    group_by(logId) %>%
    summarize(
        "Id" = min(Id),
        # Associate each Log ID with the latest date recorded under it
        "SleepDay" = max(date_floored),
        "minutes_in_bed"   = n(),
        "minutes_awake"    = sum(value == 3),
        "minutes_restless" = sum(value == 2),
        "minutes_asleep"   = sum(value == 1)) %>%
    # Sum time asleep for each date based on SleepDay
    group_by(Id, SleepDay) %>%
    summarize(
        "TotalSleepRecords_2" = n(),
        "TotalMinutesAsleep_2" = sum(minutes_asleep),
        "TotalTimeInBed_2" = sum(minutes_in_bed),
        "TotalMinutesAwake" = sum(minutes_awake),
        "TotalMinutesRestless" = sum(minutes_restless),
    ) %>%
    mutate("Id_SleepDay_UID" = paste(Id, SleepDay, sep = "_")) %>%
    arrange(Id_SleepDay_UID)

# Compare both versions of the data and return any dates with different values
sleepDay_comp <- sleep_sum_days_wide %>%
    # mutate("SleepDay_typed" = mdy_hms(SleepDay)) %>%
    mutate("SleepDay_floored" = floor_date(mdy_hms(SleepDay), unit = "days")) %>%
    mutate("Id_SleepDay_UID" = paste(Id, SleepDay_floored, sep = "_")) %>%
    arrange(Id_SleepDay_UID) %>%
    with(merge(
        .,
        sleep_sum_days_wide_test,
        by = c("Id_SleepDay_UID"),
        all = TRUE
    )
    ) %>%
    mutate(recordDiff = TotalSleepRecords_2 - TotalSleepRecords) %>%
    mutate(sleepDiff = TotalMinutesAsleep_2 - TotalMinutesAsleep) %>%
    mutate(bedDiff = TotalTimeInBed_2 - TotalTimeInBed) %>%
    select(
        Id_SleepDay_UID,
        recordDiff,
        sleepDiff,
        bedDiff
    ) %>%
    filter(!(recordDiff == 0 & sleepDiff == 0 & bedDiff == 0)) %>%
    arrange(Id_SleepDay_UID)

# For this table, glimpse() shows enough to demonstrate the validity of the method
cat("Printing all rows with non-zero diff values:\n")
glimpse(sleepDay_comp)
rm(sleep_sum_days_wide_test, sleepDay_comp)

```

The two +500-minute values were investigated and found to be the result of double-sampling in the data. That day had two duplicate logs, which in the original sum data was presented as two duplicate rows with the accurate 500-minute value, and in my data was presented as two rows with the full 1000 minutes of data summed. All other rows were identical to or within 22 minutes of the original, which I considered accurate enough to validate the mapping.

### Duplicate data between tables

The data set includes some tables that contain source data for a given feature, e.g. heart-rate tracking, and others that contain summary data, e.g. everything in the "activity_days_sum_wide" table. 

Some of these are useful, for instance: 

* dailyActivities_merged.csv calculates Sedentary Minutes by excluding time spent asleep. This either requires clever/time-consuming cross-referencing with other tables, or is raw data from a calculation performed on the FitBit itself: either way, I don't want to have to do it again
* sleepDay_merged.csv summarises sleep on a per-night basis, which is more useful for comparing users than the raw, minute-by-minute sleep data

Others are not useful, for instance: 

* calories_sum_mins_wide.csv, intensity_sum_mins_wide.csv, and steps_sum_mins_wide.csv all just pivot minute-level data into one 60-column row per hour containing the same data
* minuteIntensitiesWide_merged.csv just sums and averages intensity per hour

Those tables that do not provide useful summaries can be excluded from the data analysis: if a specific need is found for their data, they can be reloaded or recreated manually as required.

### Duplicate data within tables

The "bodycomp_logs_src_wide.csv" file contains both kilogram and pound variables: these describe the same information, and all of the observations contain values for both variables, so one variable can be dropped with no loss of data. The choice between the two formats seems arbitrary for my analysis, so I'm choosing to keep the kilos data as its expressed in an SI unit.

intensity_sum_hours_wide.csv contains Total Intensity and Average Intensity. Total intensity values exceed 4, the maximum for intensity, and so are not actually useful. Average Intensity is just the Total Intensity for each hour divided by 60 minutes per hour.

# TODO Appendixes

For these appendices, I wrote the following function to reproduce all code chunks with their labels intact for better readability

```{r apdx_fns, echo = TRUE}
# Print code inside a given code chunk with backtick header/footer
print_chunk_with_label <- function(label) {
  code <- knitr::knit_code$get(label)
  if(!is.null(code)) {
    cat("```{r",label, "}\n")
    cat(code, sep = "\n")
    cat("\n```\n\n")
  }
}
```

## Appendix A: "Prepare" Stage Code

```{r prep-apdx-labels}
prep_apdx_labs <- grep("^prep-", knitr::all_labels(), value = TRUE)
```

```{r prep-apdx-code-fn-base, eval=TRUE, results='markdown', comment=NA}
invisible(lapply(prep_apdx_labs, print_chunk_with_label))
```


## Appendix B: "Clean" Stage Code

```{r clean-apdx-labels, include=TRUE}
clean_apdx_labs <- grep("^clean-", knitr::all_labels(), value = TRUE)
```

```{r clean-apdx-code, ref.label=clean_apdx_labs, echo = TRUE, include = TRUE, eval=FALSE}
```

## Appendix C: "Analyse" Stage Code

```{r analyse-apdx-labels, include=TRUE}
analyse_apdx_labs <- grep("^analyse-", knitr::all_labels(), value = TRUE)
```

```{r analyse-apdx-code, ref.label=analyse_apdx_labs, echo = TRUE, include = TRUE, eval=FALSE}
```

## Appendix D: "Share" Stage Code

```{r share-apdx-labels, include=TRUE}
share_apdx_labs <- grep("^share-", knitr::all_labels(), value = TRUE)
```

```{r share-apdx-code, ref.label=share_apdx_labs, echo = TRUE, include = TRUE, eval=FALSE}
```